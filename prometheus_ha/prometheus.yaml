apiVersion: template.openshift.io/v1
kind: Template

metadata:
  name: prometheus_ha
  annotations:
    "openshift.io/display-name": Prometheus_ha
    description: |
      A monitoring solution to get metrics and alerts for applications running in a namespace.
    iconClass: icon-cogs
    tags: "monitoring,prometheus,time-series"

parameters:
- description: The namespace where to deploy the Prometheus service
  name: NAMESPACE
  required: true
- description: The Prometheus service account (must be created beforehand)
  name: PROMETHEUS_SA
  value: prometheus
- description: The location of the Prometheus image
  name: IMAGE_PROMETHEUS
  value: openshift/prometheus:v2.0.0
- description: The location of the AlertManager image
  name: IMAGE_ALERTMANAGER
  value: openshift/prometheus-alertmanager:v0.9.1
- description: The location of the proxy image
  name: IMAGE_PROXY
  value: openshift/oauth-proxy:v1.0.0
- description: The secret for the AlertManager
  name: ALERTMANAGER_SECRET
  generate: expression
  from: "[a-zA-Z0-9]{43}"
- description: The session secret for the proxy
  name: PROXY_SECRET
  generate: expression
  from: "[a-zA-Z0-9]{43}"

objects:
- apiVersion: v1
  kind: Service
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: prometheus-tls
  spec:
    ports:
    - name: prometheus
      port: 443
      protocol: TCP
      targetPort: 8443
    selector:
      app: prometheus

- apiVersion: v1
  kind: Service
  metadata:
    name: alertmanager
    namespace: "${NAMESPACE}"
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: alertmanager-tls
  spec:
    ports:
    - name: alertmanager
      port: 443
      protocol: TCP
      targetPort: 8443
    selector:
      app: alertmanager

- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    to:
      name: prometheus
    tls:
      termination: Reencrypt
      insecureEdgeTerminationPolicy: Redirect

- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: alertmanager
    namespace: "${NAMESPACE}"
  spec:
    to:
      name: alertmanager
    tls:
      termination: Reencrypt
      insecureEdgeTerminationPolicy: Redirect

- apiVersion: v1
  kind: Secret
  metadata:
    name: proxy
    namespace: "${NAMESPACE}"
  stringData:
    session_secret: "${PROXY_SECRET}="

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    labels:
      app: prometheus
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    selector:
      matchLabels:
        app: prometheus
    updateStrategy:
      type: RollingUpdate
    podManagementPolicy: Parallel
    replicas: 2
    template:
      metadata:
        labels:
          app: prometheus
        name: prometheus
      spec:
        serviceAccountName: "${PROMETHEUS_SA}"
        containers:
        - name: proxy
          image: ${IMAGE_PROXY}
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 8443
            name: web
          args:
          - -provider=openshift
          - -https-address=:8443
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:9090
          - -client-id=system:serviceaccount:${NAMESPACE}:${PROMETHEUS_SA}
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - '-openshift-sar={"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          volumeMounts:
          - mountPath: /etc/tls/private
            name: prometheus-tls
          - mountPath: /etc/proxy/secrets
            name: proxy-secret
        - name: prometheus
          args:
          - --storage.tsdb.retention=6h
          - --config.file=/etc/prometheus/prometheus.yml
          - --web.enable-admin-api
          #- --web.listen-address=localhost:9090
          image: ${IMAGE_PROMETHEUS}
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /etc/prometheus
            name: prometheus-config
          - mountPath: /prometheus
            name: prometheus-data
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
              #host: localhost
            initialDelaySeconds: 10
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
              #host: localhost
            initialDelaySeconds: 10
          ports:
          - containerPort: 9090
            name: web
            protocol: TCP
        restartPolicy: Always
        volumes:
        - name: prometheus-config
          configMap:
            defaultMode: 420
            name: prometheus-config
        - name: prometheus-data
          emptyDir: {}
        - name: prometheus-tls
          secret:
            secretName: prometheus-tls
        - name: proxy-secret
          secret:
            secretName: proxy

- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-config
    namespace: "${NAMESPACE}"
  data:
    prometheus.rules: |
      groups:
      - name: example-rules
        interval: 30s # defaults to global interval
        rules:
        - alert: Target Down
          expr: up == 0
          for: 1m
          annotations:
            severity: "Critical"
            message: "Instance {{ $labels.instance }} for job {{ $labels.job }} is down"

    prometheus.yml: |
      rule_files:
        - 'prometheus.rules'

      alerting:
        alertmanagers:
        - scheme: https
          tls_config:
            # the certificate is generated for the service, not the endpoint itself
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
              - "${NAMESPACE}"

          relabel_configs:
          - source_labels:
            - __meta_kubernetes_service_name
            - __meta_kubernetes_endpoint_ready
            action: keep
            regex: alertmanager;true

      scrape_configs:
      - job_name: 'prometheus'
        scheme: https
        tls_config:
          # the certificate is generated for the service, not the endpoint itself
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - "${NAMESPACE}"

        relabel_configs:
        # metrics are pulled through the OAuth proxy container
        - source_labels:
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_ready
          - __meta_kubernetes_pod_container_name
          action: keep
          regex: prometheus;true;proxy
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: instance

      - job_name: 'alertmanager'
        scheme: https
        tls_config:
          # the certificate is generated for the service, not the endpoint itself
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - "${NAMESPACE}"

        relabel_configs:
        - source_labels:
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_ready
          - __meta_kubernetes_pod_container_name
          action: keep
          regex: alertmanager;true;proxy
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: instance

      - job_name: 'endpoints'
        tls_config:
          insecure_skip_verify: true

        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - "${NAMESPACE}"

        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_endpoint_ready]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: (.+)(?::\d+);(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: service_name

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: alertmanager
    namespace: "${NAMESPACE}"
  spec:
    selector:
      matchLabels:
        app: alertmanager
    updateStrategy:
      type: RollingUpdate
    podManagementPolicy: Parallel
    replicas: 2
    template:
      metadata:
        labels:
          app: alertmanager
        name: alertmanager
      spec:
        serviceAccountName: "${PROMETHEUS_SA}"
        containers:
        - name: proxy
          image: ${IMAGE_PROXY}
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 8443
            name: web
          args:
          - -provider=openshift
          - -https-address=:8443
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:9093
          - -client-id=system:serviceaccount:${NAMESPACE}:${PROMETHEUS_SA}
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - '-openshift-sar={"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          volumeMounts:
          - mountPath: /etc/tls/private
            name: alertmanager-tls
          - mountPath: /etc/proxy/secrets
            name: proxy-secret
        - name: alertmanager
          args:
          - --log.level=debug
          - --mesh.listen-address=:6783
          # Declare only the first pod as peer otherwise the mesh library
          # messes up with "multiple connections" errors.
          - --mesh.peer=alertmanager-0.alertmanager.${NAMESPACE}.endpoints:6783
          - --mesh.password=${ALERTMANAGER_SECRET}
          - --config.file=/etc/alertmanager/alertmanager.yml
          image: "${IMAGE_ALERTMANAGER}"
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 9093
            name: web
            protocol: TCP
          volumeMounts:
          - mountPath: /etc/alertmanager
            name: alertmanager-config
          - mountPath: /alertmanager
            name: alertmanager-data

        restartPolicy: Always
        volumes:
        - name: alertmanager-config
          configMap:
            defaultMode: 420
            name: alertmanager-config
        - name: alertmanager-data
          emptyDir: {}
        - name: alertmanager-tls
          secret:
            secretName: alertmanager-tls
        - name: proxy-secret
          secret:
            secretName: proxy


- apiVersion: v1
  kind: ConfigMap
  metadata:
    label:
      app: prometheus
    name: alertmanager-config
    namespace: "${NAMESPACE}"
  data:
    alertmanager.yml: |
      global:

      # The root route on which each incoming alert enters.
      route:
        # default route if none match
        receiver: alert-buffer-wh

        # The labels by which incoming alerts are grouped together. For example,
        # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
        # be batched into a single group.
        # TODO:
        group_by: []

        # All the above attributes are inherited by all child routes and can
        # overwritten on each.

      receivers:
      - name: alert-buffer-wh
        webhook_configs:
        - url: http://localhost:9099/topics/alerts
